# AICUP-2023-Truth
## Lang
[![中文](https://img.shields.io/badge/language-%E4%B8%AD%E6%96%87-blue)](README.md)
[![English](https://img.shields.io/badge/language-English-blue)](README_EN.md)

## Environment Setup
**Hardware Requirements:**
- CPU: Intel i7-8700 (12) @ 4.600GHz 
- GPU: NVIDIA GeForce GTX 1080 Ti 
- Memory: 62.66GiB 
- VRAM: At least 10GB required
- RAM: At least 16GB required

Use docker to set up the environment:
```
sudo docker run --gpus all --shm-size=1G -v "${PWD}:/workspace" -it -p 8888:8888 autogluon/autogluon:0.7.0-cuda11.7-jupyter-ubuntu20.04-py3.9 /bin/bash
```
Start Jupyter lab:
```
jupyter lab --port=8888 --ip=0.0.0.0 --allow-root
```
Install dependencies:
```
pip install -r requirements.txt
```


## Data
- `private_test_data.jsonl`: Original private_test data
- `public_test.jsonl`: Original public_test data
- `public_train_0316.jsonl`: Original public_train_0316 data
- `public_train_0522.jsonl`: Original public_train_0522 data
- `merged.jsonl`: Training data with blank spaces removed from the claim
- `public_train.jsonl`: Data with blank spaces removed, conflict labels processed, and evidence merged based on the claim
- `public_test_data.jsonl`: Data with blank spaces removed from the claim

Data Processing Code:
- `preprocess.ipynb`: The last three pieces of data are generated by this code, mainly dealing with data cleaning, data integration, and data consistency checks.

## Training Code
`main.ipynb`: Modified from the competition's baseline code, mainly using hanlp + chinese-lert-base. The model training process is assisted by autogluon. AdamW is used as the optimizer. All training parameters and settings are in the asset.json and config.yaml files in the weight directory. Predictions are made directly after training.
- Before running, the wiki-pages need to be placed in the Data folder

## Prediction
`test.ipynb`: Modified from the competition's baseline code, mainly using hanlp + chinese-lert-base. Running all the code in test.ipynb will produce the best submission result.
- To load the model, modify these two variables after downloading the weights to load the model path:
    - `step2_model = 'step2_new_upload'` 
    - `step3_model = 'step3_new_upload'`

## Model Weights

|          Model Type           | Public Score | Private Score |                                               URL                                                |
| :---------------------------: | :----------: | :-----------: | :----------------------------------------------------------------------------------------------: |
| hanlp + chinese-lert-base * 2 |   0.592518   |   0.678255    | [Download](https://drive.google.com/drive/folders/1-4sLL-tQtZC1QEXegeoR3c6Qi3GRvkjM?usp=sharing) |

- Due to a cyber attack, the laboratory's computer was compromised, and data was deleted. This is the weight trained in the last week of the competition, and only the best model is retained.
- All the training parameters and settings of the weights are in the assets.json and config.yaml files in this directory. Most of the parameters use the default parameters of Autogluon.
